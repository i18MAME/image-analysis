・このファイル内のプログラムをそのまま実行するのはお勧めしません。githubから
　https://github.com/qqwweee/keras-yolo3
以下のファイルをダウンロードしてそれを編集しながらやることをお勧めします。
  https://farml1.com/snackpea_1/
このサイトを見ながらやるとおそらくできると思います。
(このサイトはGPUを使わずに学習させています）



・このプログラムは単体では動かない仕様になっています。ラズパイ4内のDesktop/sample に入っているsend_picture2.pyを先に実行した後に
  \ python yolo_video.py --image
と実行してください
send_picture2.py はセンサーが信号を受け取って画像をstr型に変換して信号を発信しています(カメラは1台制御)

・tensorflow 1.14 を使っているのでpythonのバージョンが3.8以上だと動きません。3.7以下の仮想環境を作って実行してください

(仮想環境の作り方 anaconda版)
Anaconda Prompt を開き
  \ conda create -n 環境名 python=バージョン
  \ conda activate 環境名
を打つ

・このプログラムでは1回しかラズパイからの信号を受け取ることができません。
しかし、send_picture2.pyではセンサーの信号を受け取るごとに画像データを発信する仕組みになっています。
(つまり、yolo_video.py 側で何回も信号を受け取る処理ができればより実践的なものにできる）

・信号を受けってから解析が終了するまでかなりの時間がかかります。


